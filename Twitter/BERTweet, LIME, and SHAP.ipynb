{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e43d1791"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFRobertaModel\n",
        "import random"
      ],
      "id": "e43d1791"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMVNgpgQnyha"
      },
      "outputs": [],
      "source": [
        "data = 'final_cleaned2.csv'"
      ],
      "id": "FMVNgpgQnyha"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeKYulHe2HP-"
      },
      "outputs": [],
      "source": [
        "def shuffle_string(string):\n",
        "    words = string.split()\n",
        "    random.shuffle(words)\n",
        "    return ' '.join(words)"
      ],
      "id": "qeKYulHe2HP-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd0f6cab"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "data = pd.read_csv(data, lineterminator='\\n')\n",
        "data = data[data['text2'].notna()]\n",
        "peaceful = ['CA', 'FI', 'GB', 'NO', 'IE', 'AU', 'SG', 'FR']\n",
        "data['peacefulness'] = data.country_code.apply(lambda x: 1 if (x in peaceful) else 0)\n",
        "data['text3'] = data['text2'].apply(shuffle_string)\n",
        "x = data['text2'].to_numpy()\n",
        "y = data['peacefulness'].to_numpy()\n",
        "y = to_categorical(data['peacefulness'])\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, random_state = 123, test_size = 0.2)\n",
        "\n",
        "sx = data['text3'].to_numpy()\n",
        "sx_train, sx_val, sy_train, sy_val = train_test_split(sx, y, random_state = 123, test_size = 0.2)"
      ],
      "id": "fd0f6cab"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Models"
      ],
      "metadata": {
        "id": "r1eJWj0ad4OW"
      },
      "id": "r1eJWj0ad4OW"
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://www.kaggle.com/code/tylerrosacker/bertweet-transfer-learning\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", \n",
        "                                          normalization=True, \n",
        "                                          use_fast = False,\n",
        "                                          add_special_tokens=True,\n",
        "                                          pad_to_max_length=True,\n",
        "                                          return_attention_mask=True)\n",
        "\n",
        "train_token = tokenizer(x_train.tolist(), \n",
        "                        padding=\"max_length\", \n",
        "                        truncation=True,\n",
        "                        return_tensors = 'tf').data\n",
        "\n",
        "val_token = tokenizer(x_val.tolist(), \n",
        "                      padding=\"max_length\", \n",
        "                      truncation=True,\n",
        "                      return_tensors = 'tf').data\n",
        "\n",
        "train_features = {x: train_token[x] for x in tokenizer.model_input_names}\n",
        "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, y_train))\n",
        "train_tf_dataset = train_tf_dataset.shuffle(len(x_train)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_features = {x: val_token[x] for x in tokenizer.model_input_names}\n",
        "val_tf_dataset = tf.data.Dataset.from_tensor_slices((val_features, y_val))\n",
        "val_tf_dataset = val_tf_dataset.shuffle(len(x_val)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "PlQl80zJ-uSc"
      },
      "id": "PlQl80zJ-uSc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1661MgYsuopY",
        "outputId": "1daceb60-26a1-4948-8b39-98e0c8d63778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base', \n",
        "                                          normalization=True, \n",
        "                                          use_fast = False,\n",
        "                                          add_special_tokens=True,\n",
        "                                          pad_to_max_length=True,\n",
        "                                          return_attention_mask=True)\n",
        "\n",
        "strain_token = tokenizer(sx_train.tolist(), \n",
        "                         padding=\"max_length\", \n",
        "                         truncation=True,\n",
        "                         return_tensors = 'tf').data\n",
        "\n",
        "sval_token = tokenizer(sx_val.tolist(), \n",
        "                       padding=\"max_length\", \n",
        "                       truncation=True,\n",
        "                       return_tensors = 'tf').data\n",
        "\n",
        "strain_features = {x: strain_token[x] for x in tokenizer.model_input_names}\n",
        "strain_tf_dataset = tf.data.Dataset.from_tensor_slices((strain_features, sy_train))\n",
        "strain_tf_dataset = strain_tf_dataset.shuffle(len(sx_train)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "sval_features = {x: sval_token[x] for x in tokenizer.model_input_names}\n",
        "sval_tf_dataset = tf.data.Dataset.from_tensor_slices((sval_features, sy_val))\n",
        "sval_tf_dataset = sval_tf_dataset.shuffle(len(sx_val)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "id": "1661MgYsuopY"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification, RobertaConfig\n",
        "config = RobertaConfig.from_pretrained('vinai/bertweet-base', num_labels = 2, dropout = 0.2)\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained('vinai/bertweet-base', config = config, trainable=True)"
      ],
      "metadata": {
        "id": "c5sHU673-qYR"
      },
      "id": "c5sHU673-qYR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLhIhcjVFiUp"
      },
      "outputs": [],
      "source": [
        "# source: https://github.com/wz2536/power-of-peace-speech_CapstoneFall2021/blob/main/Classification%20Models/fine-tune-roberta.ipynb\n",
        "def build_model(lr = 1e-5):   \n",
        "    input_ids = tf.keras.Input(shape=(128,),dtype='int32', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape=(128,), dtype='int32', name = 'attention_mask')\n",
        "\n",
        "    output = tf_model([input_ids, attention_masks])[0]\n",
        "    output = tf.keras.layers.Activation(activation='softmax')(output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks], outputs = output)\n",
        "    \n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr, clipnorm=1.),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "        \n",
        "    return model"
      ],
      "id": "OLhIhcjVFiUp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Unshuffled Tweet"
      ],
      "metadata": {
        "id": "DD9HLPRY8R2R"
      },
      "id": "DD9HLPRY8R2R"
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "history = model.fit(train_tf_dataset, epochs = 1)"
      ],
      "metadata": {
        "id": "EV_JIQp22tO2"
      },
      "id": "EV_JIQp22tO2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_tf_dataset)"
      ],
      "metadata": {
        "id": "B8W6vBTN2vY0"
      },
      "id": "B8W6vBTN2vY0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(val_token)\n",
        "pred_labels = np.argmax(yhat, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)"
      ],
      "metadata": {
        "id": "P2Trvkut2xON"
      },
      "id": "P2Trvkut2xON",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.confusion_matrix(\n",
        "    y_true,\n",
        "    pred_labels\n",
        ")"
      ],
      "metadata": {
        "id": "b8TIpNhs2zTg"
      },
      "id": "b8TIpNhs2zTg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Shuffled Tweet"
      ],
      "metadata": {
        "id": "l0cFyNK88cQr"
      },
      "id": "l0cFyNK88cQr"
    },
    {
      "cell_type": "code",
      "source": [
        "smodel = build_model()\n",
        "shistory = smodel.fit(strain_tf_dataset, epochs = 1)"
      ],
      "metadata": {
        "id": "-ffpwo0y22Om"
      },
      "id": "-ffpwo0y22Om",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smodel.evaluate(sval_tf_dataset)"
      ],
      "metadata": {
        "id": "zDz8itgA232Z"
      },
      "id": "zDz8itgA232Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syhat = smodel.predict(sval_token)\n",
        "spred_labels = np.argmax(syhat, axis=1)\n",
        "sy_true = np.argmax(sy_val, axis=1)"
      ],
      "metadata": {
        "id": "jvCNNGGe254R"
      },
      "id": "jvCNNGGe254R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.confusion_matrix(\n",
        "    sy_true,\n",
        "    spred_labels\n",
        ")"
      ],
      "metadata": {
        "id": "ERfeKVJQ28_i"
      },
      "id": "ERfeKVJQ28_i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIME"
      ],
      "metadata": {
        "id": "xly545SF9Qi-"
      },
      "id": "xly545SF9Qi-"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_probs(texts):\n",
        "    text_token = tokenizer(texts, \n",
        "                           padding=\"max_length\", \n",
        "                           truncation=True,\n",
        "                           return_tensors = 'tf').data\n",
        "    predictions = model.predict(text_token)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "7kcVqgI89abd"
      },
      "id": "7kcVqgI89abd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime import lime_text\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "class_names = ['low peace','high peace']\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "i = 0\n",
        "STR = str(x_val[i])\n",
        "exp = explainer.explain_instance(STR, predict_probs)"
      ],
      "metadata": {
        "id": "2JvYhe7X9UyZ"
      },
      "id": "2JvYhe7X9UyZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.show_in_notebook(text=False)"
      ],
      "metadata": {
        "id": "HWiUcXgO-zYi"
      },
      "id": "HWiUcXgO-zYi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP"
      ],
      "metadata": {
        "id": "0WiN_X5t9-Tn"
      },
      "id": "0WiN_X5t9-Tn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i97V69fPlhr"
      },
      "outputs": [],
      "source": [
        "import shap"
      ],
      "id": "7i97V69fPlhr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ4kzN9TuqH-"
      },
      "outputs": [],
      "source": [
        "def predict_probs2(texts):\n",
        "    texts = [str(text) for text in texts]\n",
        "    text_token = tokenizer(texts, \n",
        "                           padding=\"max_length\", \n",
        "                           truncation=True,\n",
        "                           return_tensors = 'tf').data\n",
        "    predictions = model.predict(text_token)\n",
        "    return predictions"
      ],
      "id": "XJ4kzN9TuqH-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9OLSFpInSjX"
      },
      "outputs": [],
      "source": [
        "class_names = ['low peace','high peace']\n",
        "explainer = shap.Explainer(predict_probs2, tokenizer, output_names=class_names)"
      ],
      "id": "V9OLSFpInSjX"
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer(x_val[:5].tolist(), fixed_context=1)"
      ],
      "metadata": {
        "id": "lPoD0yt998en"
      },
      "id": "lPoD0yt998en",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values[:5])"
      ],
      "metadata": {
        "id": "Rm2Zzpm9-cFu"
      },
      "id": "Rm2Zzpm9-cFu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}