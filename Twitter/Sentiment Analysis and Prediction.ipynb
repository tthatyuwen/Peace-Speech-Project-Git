{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8cf9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20b4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis with sample data\n",
    "data = 'sample.csv'\n",
    "subsample = pd.read_csv(data, lineterminator='\\n')\n",
    "tweet = subsample[['text', 'country_code']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0067e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {'IN': 'India', 'IR': 'Iran', 'NG': 'Nigeria', 'UG': 'Uganda',\n",
    "             'GM': 'Gambia', 'LY': 'Libya', 'PK': 'Pakistan', 'ZW': 'Zimbabwe',\n",
    "             'CA': 'Canada', 'GB': 'United Kingdom', 'FI': 'Finland', 'NO': 'Norway',\n",
    "             'IE': 'Ireland', 'FR': 'France', 'AU': 'Australia', 'SG': 'Singapore'}\n",
    "tweet['country'] = tweet['country_code'].apply(lambda x: countries[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d904fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess based on hugging face instructions\n",
    "# source: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if \"http\" in t else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bc4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['new_text'] = tweet.text.apply(func = preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67210dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26bf07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "Roberta = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Roberta)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(Roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e365ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "# source: https://medium.com/mlearning-ai/elon-musks-twitter-sentiment-analysis-with-transformers-hugging-face-roberta-49b9e61b1433\n",
    "# source: https://github.com/huggingface/transformers/issues/16746\n",
    "def sentiment_score(tweets):\n",
    "    try:\n",
    "        tokens = tokenizer.encode(tweets, return_tensors='pt', truncation=True, max_length = 511)\n",
    "        output = model(tokens)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        return scores\n",
    "    except RuntimeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429dfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['sentiment'] = tweet['new_text'].apply(func = sentiment_score)\n",
    "tweet['sentiment_classification'] = tweet['sentiment'].apply(np.argmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a4e16",
   "metadata": {},
   "source": [
    "# Exploratary Analysis of Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average sentiment score by country\n",
    "avg_by_country = tweet['sentiment_classification'].groupby(tweet['country_code', 'country']).mean().to_frame()\n",
    "avg_by_country = avg_by_country.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddcdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.barplot(x = 'country_code',\n",
    "            y = 'sentiment_classification',\n",
    "            palette = 'colorblind',\n",
    "            data = avg_by_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification count by country and classification\n",
    "count_by_country = tweet.groupby(['sentiment_classification','country_code', 'country'], as_index=False).size()\n",
    "count_by_country = count_by_country.sort_values(by = ['sentiment_classification', 'size'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c096de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'country_code',\n",
    "            y = 'size',\n",
    "            col = 'sentiment_classification',\n",
    "            kind = 'bar',\n",
    "            palette = 'colorblind',\n",
    "            data = count_by_country\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd286b3",
   "metadata": {},
   "source": [
    "# Predicting Peacefulness with Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3076d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with random forest / logistic regression\n",
    "from random import sample\n",
    "full = 'sample.csv'\n",
    "tweets = pd.read_csv(full, lineterminator='\\n')\n",
    "text = tweets[['text', 'country_code']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated sampling 300 data points for each country and calculate their corresponding statistics\n",
    "rframe = []\n",
    "rframe1 = []\n",
    "rframe2 = []\n",
    "for i in range (20):\n",
    "    sample = text.groupby('country_code', group_keys = False).apply(lambda x: x.sample(300))\n",
    "    text = pd.concat([text, sample]).drop_duplicates(keep = False)\n",
    "    sample['new_text'] = sample.text.apply(func = preprocess)\n",
    "    sample['sentiment'] = sample['new_text'].apply(func = sentiment_score)\n",
    "    sample['sentiment_classification'] = sample['sentiment'].apply(np.argmax)\n",
    "    rframe.append(sample)\n",
    "    s_avg_by_country = sample['sentiment_classification'].groupby(sample['country_code']).mean().to_frame().reset_index(level=0)\n",
    "    s_count_by_country = sample.groupby(['sentiment_classification','country_code'], as_index = False).size()\n",
    "    s_count_by_country = s_count_by_country.pivot(index = 'country_code', columns = 'sentiment_classification', values='size').rename_axis(None, axis=1)\n",
    "    s_count_by_country = (s_count_by_country/300).reset_index(level = 0)\n",
    "    rframe1.append(s_avg_by_country)\n",
    "    rframe2.append(s_count_by_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(rframe)\n",
    "result1 = pd.concat(rframe1)\n",
    "result2 = pd.concat(rframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaceful = ['AU', 'CA', 'FI', 'FR', 'GB', 'IE', 'NO', 'SG']\n",
    "result1['peacefulness'] = result1.country_code.apply(lambda x: 1 if (x in peaceful) else 0)\n",
    "result2['peacefulness'] = result2.country_code.apply(lambda x: 1 if (x in peaceful) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e897665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "x = result1['sentiment_classification'].to_frame()\n",
    "y = result1['peacefulness']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30)\n",
    "param_grid = {\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 100, num = 10)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "}\n",
    "\n",
    "hyper_tuning = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                            param_grid = param_grid,\n",
    "                            cv = 5)\n",
    "\n",
    "hyper_tuning.fit(x_train, y_train)\n",
    "hyper_tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 50, n_estimators = 200, n_jobs = -1)\n",
    "rf.fit(x_train, y_train)\n",
    "yhat = rf.predict(x_test)\n",
    "print(rf.score(x_train, y_train))\n",
    "print(rf.score(x_test, y_test))\n",
    "print(f1_score(y_test, yhat))\n",
    "plot_confusion_matrix(rf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p = result2[['0', '2']]\n",
    "y_p = result2['peacefulness']\n",
    "xp_train, xp_test, yp_train, yp_test = train_test_split(x_p, y_p, test_size = 0.30)\n",
    "\n",
    "hyper_tuning.fit(xp_train, yp_train)\n",
    "hyper_tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp = RandomForestClassifier(max_depth = 10, n_estimators = 1400, n_jobs = -1)\n",
    "rfp.fit(xp_train, yp_train)\n",
    "yphat = rfp.predict(xp_test)\n",
    "print(rfp.score(xp_train, yp_train))\n",
    "print(rfp.score(xp_test, yp_test))\n",
    "print(f1_score(yp_test, yphat))\n",
    "plot_confusion_matrix(rfp, xp_test, yp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "print(logreg.coef_, logreg.intercept_)\n",
    "print(logreg.score(x_train, y_train))\n",
    "print(logreg.score(x_test, y_test))\n",
    "plot_confusion_matrix(logreg, x_test, y_test)\n",
    "\n",
    "logreg.fit(xp_train, yp_train)\n",
    "print(logreg.coef_, logreg.intercept_)\n",
    "print(logreg.score(xp_train, yp_train))\n",
    "print(logreg.score(xp_test, yp_test))\n",
    "plot_confusion_matrix(logreg, xp_test, yp_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
