{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxprrHjkt-5F",
        "outputId": "3bb07558-74d3-491d-fd37-163b772ffbcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsB6JNtUuwjL",
        "outputId": "43b1cb78-25a3-4864-96d5-36ec748ad84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: highlight_text in /usr/local/lib/python3.7/dist-packages (0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install highlight_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKApAkqQt9Wn",
        "outputId": "832a1b8b-5a4c-44a4-d51a-8028eecd0c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Yi_rRm0glkRO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import sentencepiece\n",
        "from transformers import XLNetTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification,XLNetConfig\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7bU8HwUuH0M",
        "outputId": "36c8a4d4-f864-43fc-eb77-8a5918aa7707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZCGcBw6ujBs",
        "outputId": "61591812-2024-45c1-f07a-51c46f8f99ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "75OOocSwuoiy"
      },
      "outputs": [],
      "source": [
        "def colorize(words, color_array):\n",
        "    cmap=matplotlib.cm.Blues\n",
        "    template = '{}\">{}'\n",
        "    colored_string = ''\n",
        "    length = 0\n",
        "    line_len = 50\n",
        "    for word, color in zip(words, color_array):\n",
        "        if (length + len(word)) // line_len  - length // line_len == 1:\n",
        "            word += '\\n'\n",
        "        length += len(word)\n",
        "        color *= 0.8\n",
        "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
        "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
        "\n",
        "    #display(HTML(colored_string))\n",
        "    return colored_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISYCuilwREWT",
        "outputId": "983758df-e164-412b-f8d5-e309b0b368fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtm46QZOlcDE",
        "outputId": "95077a3c-f3ff-4c4f-89dd-f6137997f5bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "output_dir = \"./drive/MyDrive/capstone/XLNet_Trained_Model/model_save/\"\n",
        "config = XLNetConfig.from_pretrained(output_dir, output_attentions=True)\n",
        "model =  XLNetForSequenceClassification.from_pretrained(output_dir, config=config)\n",
        "tokenizer = XLNetTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "feBjqRJRu3k1"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('drive/MyDrive/capstone/Test_Data.csv')\n",
        "df = data.loc[:,['cleaned_text','peace']]\n",
        "df.rename(columns = {'peace':'label','cleaned_text':'text'}, inplace = True)\n",
        "df.text = df.text.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Z5n07Y3-zSSg"
      },
      "outputs": [],
      "source": [
        "def get_attention_score(text):\n",
        "    encodings = tokenizer([text], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "      output = model(input_ids=input_ids, attention_mask=attention_mask)[2]\n",
        "\n",
        "    att_sum = output[0].cpu().reshape(12, len(input_ids[0]), len(input_ids[0])).sum(axis=[0, 1]).numpy()\n",
        "    # ignore [CLS] and [SEP] in bert tokens\n",
        "    return att_sum[1: -1] / max(att_sum[1: -1], default = 0), input_ids.cpu()[0][1: -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tFEWpuVh2g-h"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "\n",
        "def get_global_attr_score_sum(list_of_texts):\n",
        "    attr_score_sum_vec = np.zeros(VOCAB_SIZE)\n",
        "    word_freq_vec = np.zeros(VOCAB_SIZE)\n",
        "\n",
        "    for text in tqdm(list_of_texts):\n",
        "        attr_score, input_ids = get_attention_score(text)\n",
        "        word_freq_vec[input_ids.numpy()] += 1\n",
        "        attr_score_sum_vec[input_ids.numpy()] += attr_score\n",
        "\n",
        "    return attr_score_sum_vec, word_freq_vec\n",
        "\n",
        "\n",
        "def get_top_words(word_weight_vec, n):\n",
        "    top_n_indices = np.argsort(word_weight_vec)[::-1][:n]\n",
        "    top_weight_vec = word_weight_vec[top_n_indices]\n",
        "    return tokenizer.convert_ids_to_tokens(top_n_indices), top_weight_vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8RkbNB802le6"
      },
      "outputs": [],
      "source": [
        "pos_data = df[df['label'] == 1].reset_index(drop=True)\n",
        "neg_data = df[df['label'] == 0].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFDcGpHD26bz",
        "outputId": "30b4e610-0d76-4dc4-d7ba-e9918f75f935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/61688 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 61688/61688 [20:28<00:00, 50.22it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['british',\n",
              "  'european',\n",
              "  '▁meanwhile',\n",
              "  '▁accuse',\n",
              "  '▁allege',\n",
              "  '▁example',\n",
              "  '▁spokesman',\n",
              "  'canadian',\n",
              "  '▁headline',\n",
              "  '▁amid',\n",
              "  '▁advertise',\n",
              "  '▁ago',\n",
              "  '▁involve',\n",
              "  '▁announce',\n",
              "  '▁injure',\n",
              "  '▁pandemic',\n",
              "  '▁include',\n",
              "  '▁despite',\n",
              "  '▁election',\n",
              "  'chinese',\n",
              "  '<sep>',\n",
              "  '▁largest',\n",
              "  'american',\n",
              "  '▁statement',\n",
              "  '▁investigate',\n",
              "  '▁politician',\n",
              "  '▁arrive',\n",
              "  '▁celebrate',\n",
              "  '▁country',\n",
              "  '▁decade',\n",
              "  '▁describe',\n",
              "  '▁nation',\n",
              "  '▁million',\n",
              "  '▁warn',\n",
              "  '▁determine',\n",
              "  '▁allow',\n",
              "  '▁vote',\n",
              "  '▁parliament',\n",
              "  '▁incident',\n",
              "  '▁require',\n",
              "  '▁admit',\n",
              "  '▁allegedly',\n",
              "  '▁scene',\n",
              "  'african',\n",
              "  '▁allegation',\n",
              "  '▁arrest',\n",
              "  '▁week',\n",
              "  '▁investigation',\n",
              "  '▁confirm',\n",
              "  '▁resign',\n",
              "  '▁interview',\n",
              "  '▁french',\n",
              "  '▁yesterday',\n",
              "  '▁latest',\n",
              "  '▁billion',\n",
              "  '▁former',\n",
              "  '▁biggest',\n",
              "  '▁authority',\n",
              "  '▁decide',\n",
              "  '▁journalist',\n",
              "  '▁ensure',\n",
              "  '▁argue',\n",
              "  '▁reveal',\n",
              "  '▁favourite',\n",
              "  '▁however',\n",
              "  '▁disappoint',\n",
              "  '▁agree',\n",
              "  '▁dozen',\n",
              "  '▁begin',\n",
              "  '▁minister',\n",
              "  '▁cite',\n",
              "  '▁estimate',\n",
              "  '▁murder',\n",
              "  '▁crowd',\n",
              "  '▁prosecutor',\n",
              "  '▁website',\n",
              "  '▁insist',\n",
              "  '▁month',\n",
              "  '▁lawmaker',\n",
              "  '▁criticism',\n",
              "  '▁concern',\n",
              "  'year',\n",
              "  '▁propose',\n",
              "  '▁defeat',\n",
              "  '▁whether',\n",
              "  '▁story',\n",
              "  '▁among',\n",
              "  '▁article',\n",
              "  '▁crisis',\n",
              "  '▁hospital',\n",
              "  '▁indicate',\n",
              "  '▁reporter',\n",
              "  '▁publish',\n",
              "  '▁understand',\n",
              "  '▁due',\n",
              "  '▁century',\n",
              "  '▁career',\n",
              "  '▁police',\n",
              "  '▁violence',\n",
              "  '▁suggest'],\n",
              " array([0.88658527, 0.88096511, 0.87222917, 0.86357128, 0.86340224,\n",
              "        0.85415811, 0.84741878, 0.84092543, 0.82742058, 0.81977479,\n",
              "        0.81625924, 0.81367995, 0.81096817, 0.81058624, 0.80250707,\n",
              "        0.79665945, 0.78872617, 0.77766999, 0.777373  , 0.77688071,\n",
              "        0.77645066, 0.77541335, 0.77435583, 0.77329417, 0.77013709,\n",
              "        0.76649895, 0.76436247, 0.75681514, 0.75644234, 0.75630831,\n",
              "        0.751998  , 0.74684502, 0.74680757, 0.74488407, 0.74399249,\n",
              "        0.74376495, 0.74067526, 0.74018578, 0.74015649, 0.73878571,\n",
              "        0.73871692, 0.73825235, 0.73768878, 0.73742553, 0.73713831,\n",
              "        0.73403428, 0.73137963, 0.73113779, 0.72928829, 0.72825621,\n",
              "        0.72751555, 0.72601137, 0.72449857, 0.72439127, 0.72404486,\n",
              "        0.72381978, 0.72301197, 0.72243769, 0.72104292, 0.72012317,\n",
              "        0.72005243, 0.71966378, 0.71928261, 0.718122  , 0.71811138,\n",
              "        0.71756239, 0.71752817, 0.71745335, 0.71626951, 0.71584784,\n",
              "        0.71542435, 0.71515615, 0.71514923, 0.715133  , 0.71382026,\n",
              "        0.71360937, 0.7132593 , 0.71320518, 0.71278019, 0.7127349 ,\n",
              "        0.71181224, 0.71120951, 0.71023853, 0.70901275, 0.70872137,\n",
              "        0.70835243, 0.70826707, 0.70826505, 0.70784517, 0.70634895,\n",
              "        0.70624132, 0.70611392, 0.70585503, 0.70584395, 0.70570982,\n",
              "        0.7054448 , 0.70502202, 0.70501759, 0.70492362, 0.70454261]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pos_attr_score_sum_vec, pos_word_freq_vec = get_global_attr_score_sum(pos_data['text'])\n",
        "pos_attr_score_avg_vec = pos_attr_score_sum_vec / (pos_word_freq_vec + 200)\n",
        "pos_top_words, pos_top_weights = get_top_words(pos_attr_score_avg_vec, 100)\n",
        "pos_top_words, pos_top_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8kPZ0KD8DXJ",
        "outputId": "df444e98-9322-4eb3-ba6b-fca355cfcad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 62025/62025 [20:38<00:00, 50.10it/s]\n"
          ]
        }
      ],
      "source": [
        "neg_attr_score_sum_vec, neg_word_freq_vec = get_global_attr_score_sum(neg_data['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PSIKTx-E8Fxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddb8a26-bd58-4ec1-be13-0a2740caf6d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['▁allege',\n",
              "  '▁accuse',\n",
              "  'according',\n",
              "  'african',\n",
              "  '▁meanwhile',\n",
              "  '▁remark',\n",
              "  '▁announce',\n",
              "  '▁appoint',\n",
              "  '▁spokesperson',\n",
              "  '▁example',\n",
              "  'european',\n",
              "  '▁allegedly',\n",
              "  '▁involve',\n",
              "  '▁indicate',\n",
              "  '▁cooperation',\n",
              "  '▁spokesman',\n",
              "  '▁ago',\n",
              "  '▁include',\n",
              "  '▁statement',\n",
              "  '▁conclude',\n",
              "  '▁election',\n",
              "  '▁ceremony',\n",
              "  '▁disclose',\n",
              "  '▁allegation',\n",
              "  '▁violation',\n",
              "  '▁pandemic',\n",
              "  '▁despite',\n",
              "  '▁inform',\n",
              "  '▁constitution',\n",
              "  '▁respectively',\n",
              "  '▁ensure',\n",
              "  '<sep>',\n",
              "  '▁facilitate',\n",
              "  '▁country',\n",
              "  '▁promote',\n",
              "  '▁sanction',\n",
              "  '▁chairman',\n",
              "  'british',\n",
              "  '▁reiterate',\n",
              "  '▁journalist',\n",
              "  '▁defeat',\n",
              "  '▁arrest',\n",
              "  '▁nation',\n",
              "  '▁require',\n",
              "  '▁regard',\n",
              "  '▁addition',\n",
              "  '▁describe',\n",
              "  '▁achieve',\n",
              "  '▁commence',\n",
              "  '▁implement',\n",
              "  '▁injure',\n",
              "  '▁implementation',\n",
              "  '▁declare',\n",
              "  '▁politician',\n",
              "  '▁arrive',\n",
              "  '▁celebrate',\n",
              "  '▁behalf',\n",
              "  '▁instance',\n",
              "  '▁interview',\n",
              "  '▁institution',\n",
              "  '▁million',\n",
              "  '▁yesterday',\n",
              "  '▁allow',\n",
              "  '▁comprise',\n",
              "  '▁secretary',\n",
              "  '▁quote',\n",
              "  '▁tourism',\n",
              "  '▁determine',\n",
              "  '▁parliament',\n",
              "  '▁confirm',\n",
              "  '▁adjourn',\n",
              "  '▁therefore',\n",
              "  '▁cite',\n",
              "  '▁commend',\n",
              "  '▁minister',\n",
              "  '▁incident',\n",
              "  '▁decide',\n",
              "  '▁assure',\n",
              "  '▁province',\n",
              "  '▁investigate',\n",
              "  '▁billion',\n",
              "  '▁however',\n",
              "  '▁relate',\n",
              "  '▁authority',\n",
              "  '▁propose',\n",
              "  '▁sector',\n",
              "  '▁organize',\n",
              "  '▁encourage',\n",
              "  '▁importance',\n",
              "  '▁delegation',\n",
              "  '▁football',\n",
              "  '▁week',\n",
              "  '▁reportedly',\n",
              "  '▁among',\n",
              "  '▁attend',\n",
              "  '▁towards',\n",
              "  '▁participate',\n",
              "  '▁achievement',\n",
              "  '▁due',\n",
              "  '▁reveal'],\n",
              " array([0.90433602, 0.89927061, 0.87331109, 0.86787006, 0.83810575,\n",
              "        0.82955805, 0.82258875, 0.82152045, 0.80771153, 0.80684624,\n",
              "        0.80481606, 0.80247823, 0.80107018, 0.80075011, 0.79752112,\n",
              "        0.79317816, 0.79287358, 0.78959687, 0.78617216, 0.78070867,\n",
              "        0.77845558, 0.77789041, 0.77650027, 0.77275203, 0.77233011,\n",
              "        0.77101669, 0.77066362, 0.76833327, 0.76832359, 0.76560055,\n",
              "        0.763806  , 0.76321935, 0.76256579, 0.76146632, 0.76117381,\n",
              "        0.75857974, 0.75759414, 0.75753834, 0.75680983, 0.75186822,\n",
              "        0.75160219, 0.7502856 , 0.75026788, 0.74904951, 0.74884305,\n",
              "        0.74625063, 0.74476191, 0.7430301 , 0.74294477, 0.74262779,\n",
              "        0.74144423, 0.73989913, 0.73967794, 0.73953565, 0.73921498,\n",
              "        0.73815983, 0.73811175, 0.73808998, 0.73730858, 0.73720695,\n",
              "        0.73719531, 0.73656726, 0.7364815 , 0.73579968, 0.73576373,\n",
              "        0.73349049, 0.73331326, 0.73317814, 0.73274561, 0.73257307,\n",
              "        0.73183162, 0.73170779, 0.73094405, 0.73064639, 0.72959912,\n",
              "        0.72896439, 0.72891136, 0.72888802, 0.72862609, 0.72772777,\n",
              "        0.72737811, 0.72696945, 0.72644941, 0.72598757, 0.7259285 ,\n",
              "        0.7251052 , 0.72465771, 0.72456754, 0.7242111 , 0.72389809,\n",
              "        0.72285615, 0.72276724, 0.72241564, 0.72240566, 0.7221829 ,\n",
              "        0.72172893, 0.72167835, 0.72143613, 0.72123472, 0.72088343]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "neg_attr_score_avg_vec = neg_attr_score_sum_vec / (neg_word_freq_vec + 200)\n",
        "neg_top_words, neg_top_weights = get_top_words(neg_attr_score_avg_vec, 100)\n",
        "neg_top_words, neg_top_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "uhc4OGYnDl48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63980e12-8f4d-494f-f52d-70761e806535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "sentences = df['text'].values\n",
        "labels = df['label'].values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 128,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6HtbxYAnDvx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73c9d41-d5be-4044-f166-027ea38ff6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zne2jS9bD1OL"
      },
      "outputs": [],
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IOQ0yLZBD3Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc6c08e-01eb-4d16-e91b-352683259ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tn: 56016 fp: 3827 fn: 6009 tp: 57861\n",
            "[[56016  3827]\n",
            " [ 6009 57861]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "(tn, fp), (fn, tp) = confusion_matrix(flat_predictions, flat_true_labels)\n",
        "print('tn:', tn, 'fp:', fp, 'fn:', fn, 'tp:', tp)\n",
        "print(confusion_matrix(flat_predictions, flat_true_labels))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}